{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique customers 101\n"
     ]
    }
   ],
   "source": [
    "#Loading the libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout   \n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "\n",
    "# Reading csv file\n",
    "#customers timeseries updated has data for 100 customers\n",
    "df = pd.read_csv(\"customers_timeseries_updated.csv\")\n",
    "#only using required columns for modelling\n",
    "df = df[['client_debtor_number','dates','fv_cost']]\n",
    "# number of unique customers in the data\n",
    "print(\"number of unique customers\",len(df['client_debtor_number'].unique()))\n",
    "\n",
    "# subsetting one customer data from the set\n",
    "# 1015193,7370830\n",
    "df_1015130 = df[df['client_debtor_number'] == 1015193]\n",
    "del df_1015130['client_debtor_number']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#weekly predictions\n",
    "df_1015130['dates'] = pd.to_datetime(df_1015130['dates'],format= '%d/%m/%Y')\n",
    "#weekly data\n",
    "week_data = df_1015130.set_index('dates').resample('1W').mean()\n",
    "#week_data['dates'] = pd.to_datetime(week_data['dates'], errors='coerce')\n",
    "week_data['dates'] = week_data.index.values\n",
    "#week_data = week_data.resample('1W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3478"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_1015130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fv_cost</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fv_cost      dates\n",
       "dates                         \n",
       "2010-01-03      0.0 2010-01-03\n",
       "2010-01-10      0.0 2010-01-10\n",
       "2010-01-17      0.0 2010-01-17\n",
       "2010-01-24      0.0 2010-01-24\n",
       "2010-01-31      0.0 2010-01-31"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# splitting train and test datasets \n",
    "#training 2010-2017, testing on 2018 data\\\n",
    "train_x = week_data[~(week_data['dates'].dt.year == 2018)]\n",
    "test_x = week_data[week_data['dates'].dt.year == 2018]\n",
    "#resetting index values\n",
    "train_x.reset_index(drop=True,inplace=True)\n",
    "test_x.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#sorting data based on dates\n",
    "train_x['dates'] = pd.to_datetime(train_x['dates'],format= '%d/%m/%Y')\n",
    "train_x.sort_values(by='dates',inplace=True)\n",
    "test_x['dates'] = pd.to_datetime(test_x['dates'],format= '%d/%m/%Y')\n",
    "test_x.sort_values(by='dates',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 1, 3)\n",
      "(415,)\n"
     ]
    }
   ],
   "source": [
    "# lag_feature function is used to get new column in the dataframe with \n",
    "#lagged data,number of lags can be given as function parameter \n",
    "def lag_feature(df, lag=1):\n",
    "    if not type(df) == pd.DataFrame:\n",
    "        df = pd.DataFrame(df, columns=['fv_cost'])   \n",
    "    def rename_lag(ser, j):\n",
    "        ser.name = ser.name + f'_{j}'\n",
    "        return ser        \n",
    "    # add a column lagged by `i` steps\n",
    "    for i in range(1, lag + 1):\n",
    "        df = df.join(df.fv_cost.shift(i).pipe(rename_lag, i))\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "# Prepare training data function is used to scale the fv_cost values \n",
    "# between -1 to 1 and calls lag_feature to create lag columns \n",
    "def prepare_training_data(series_data, lag):\n",
    "    \" Converts a series of data into a lagged, scaled sample.\"\n",
    "    # scale training data\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    #when diff is used don't use values\n",
    "    #cost_vals = scaler.fit_transform(series_data.values.reshape(-1, 1))   \n",
    "    cost_vals = scaler.fit_transform(series_data.values.reshape(-1, 1))\n",
    "    # convert series to lagged features\n",
    "    cost_lagged = lag_feature(cost_vals, lag=lag)\n",
    "    # X, y format taking the first column (original time series) to be the y\n",
    "    X = cost_lagged.drop('fv_cost', axis=1).values\n",
    "    y = cost_lagged.fv_cost.values\n",
    "    \n",
    "    # keras expects 3 dimensional X\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])   \n",
    "    return X, y, scaler\n",
    "\n",
    "def prepare_training_data_tensorflow(series_data, lag):\n",
    "    \" Converts a series of data into a lagged, scaled sample.\"\n",
    "    # scale training data\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    #when diff is used don't use values\n",
    "    #cost_vals = scaler.fit_transform(series_data.values.reshape(-1, 1))   \n",
    "    cost_vals = scaler.fit_transform(series_data.values.reshape(-1, 1))\n",
    "    # convert series to lagged features\n",
    "    cost_lagged = lag_feature(cost_vals, lag=lag)\n",
    "    # X, y format taking the first column (original time series) to be the y\n",
    "    X = cost_lagged.drop('fv_cost', axis=1).values\n",
    "    y = cost_lagged.fv_cost.values\n",
    "    \n",
    "    # keras expects 3 dimensional X\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)   \n",
    "    return X, y, scaler\n",
    "\n",
    "#Difference function is get lag difference values\n",
    "def difference(dataset):\n",
    "    interval=1\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        #print (\"iteration \",i)\n",
    "        value = (dataset.iloc[i] - dataset.iloc[i - interval])/(1+abs(dataset.iloc[i - interval]))\n",
    "        diff.append(value)\n",
    "    return diff\n",
    "\n",
    "# if you are using difference lag values use this code\n",
    "#diff_train = np.array(difference(train_x['fv_cost']))\n",
    "#diff_test = np.array(difference(test_x['fv_cost']))\n",
    "#train_x_cust,train_y_cust, scalar_train = prepare_training_data(diff_train, 3)\n",
    "#test_x_cust,test_y_cust,scalar_test = prepare_training_data(diff_test, 3)\n",
    "# preparing data on train and test fv_cost column values\n",
    "train_x_cust,train_y_cust, scalar_train = prepare_training_data(train_x['fv_cost'], 3)\n",
    "test_x_cust,test_y_cust,scalar_test = prepare_training_data(test_x['fv_cost'], 3)\n",
    "print(train_x_cust.shape)\n",
    "print(train_y_cust.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for one timestep\n",
    "def lstm_model(train_x, train_y,lag=3,num_neurons=50):\n",
    "    # Model description\n",
    "    # lag is number of lags used to prepare the data\n",
    "    #lag =  3\n",
    "    # model parameters\n",
    "    #num_neurons = 50 #number of neurons/nodes for the layer\n",
    "    # actually we can give data in batches to the model\n",
    "    # number of samples in the data should be divisible by batch size\n",
    "    # we are giving all data for a customer as one batch\n",
    "    batch_size = 1  \n",
    "    # input_shape as required by LSTM layer\n",
    "    batch_input_shape=(batch_size, 1, lag)\n",
    "    # dropout rate used in dropout layer\n",
    "    dropout_rate =0.2\n",
    "    # instantiate a sequential model\n",
    "    model = Sequential()\n",
    "    #add convolution layer\n",
    "    # input_shape=(3,1) 3 lags columns and 1 y value\n",
    "    # when strides>1 you cannot have dilation>1\n",
    "    # activation_func options ['softmax', 'softplus', 'softsign', 'relu', \n",
    "    #                   'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "    # in conv1D layer we can modify filters,kernel_size,strides and activation\n",
    "    # parameters\n",
    "    model.add(Conv1D(filters=num_neurons,batch_size=1, kernel_size=3, strides=3, \n",
    "                 padding=\"same\",activation='linear',dilation_rate=1, \n",
    "                 input_shape=(1, 3),data_format='channels_first'))\n",
    "    # maxpooling layers tries to reduce the features by taking maximum value for\n",
    "    # window/pool size selected,strides and pool_size can be changed\n",
    "    model.add(MaxPooling1D(pool_size=3,strides=3, padding=\"same\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # add LSTM layer - stateful MUST be true here in \n",
    "    # order to learn the patterns within a series\n",
    "    model.add(LSTM(units=num_neurons, \n",
    "              batch_input_shape=batch_input_shape, return_sequences=False,# as we only want last hidden output \n",
    "              stateful=True))\n",
    "    # output layer\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    # compile the model with required loss and optimizer function\n",
    "    adam = optimizers.Adam(lr=0.01, decay=0.01)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "    model.fit(train_x, train_y, epochs=10, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss: 0.0441\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.0671\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.0218\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.0171\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.0133\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.0126\n",
      "Epoch 7/10\n",
      " - 5s - loss: 0.0115\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.0116\n",
      "Epoch 9/10\n",
      " - 5s - loss: 0.0106\n",
      "Epoch 10/10\n",
      " - 5s - loss: 0.0094\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model(train_x_cust,train_y_cust,3,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    xplaceholder = tf.placeholder(tf.float32,[None,n_features,1])\n",
    "    yplaceholder = tf.placeholder(tf.float32,[None, n_features,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 10000\n",
    "batch_size = 128\n",
    "display_step = 200\n",
    "\n",
    "timesteps = 1\n",
    "n_output = 1\n",
    "n_hidden = 20 # number of hidden neurons\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_output]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "    n_features = 3\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    #x = tf.unstack(x, 3, 1)\n",
    "    x = tf.unstack(x, 3, 1)\n",
    "    #x = tf.split(x, n_features, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(n_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    #outputs, states = tf.nn.dynamic_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    \n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"rnn/lstm_cell/kernel:0\", shape=(21, 80), dtype=float32_ref) must be from the same graph as Tensor(\"concat:0\", shape=(?, 21), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8c24bdd91f6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxplaceholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-b05e331b4b07>\u001b[0m in \u001b[0;36mRNN\u001b[0;34m(x, weights, biases)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Get lstm cell output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#outputs, states = tf.nn.dynamic_rnn(lstm_cell, x, dtype=tf.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mstatic_rnn\u001b[0;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             state_size=cell.state_size)\n\u001b[1;32m   1376\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;31m# Keras RNN cells only return state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mvarscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0;31m# pylint: disable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m       \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m       \u001b[0;31m# pylint: enable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     return base_layer.Layer.__call__(self, inputs, state, scope=scope,\n\u001b[0;32m--> 370\u001b[0;31m                                      *args, **kwargs)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, state)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;31m# i = input_gate, j = new_input, f = forget_gate, o = output_gate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     lstm_matrix = math_ops.matmul(\n\u001b[0;32m--> 993\u001b[0;31m         array_ops.concat([inputs, m_prev], 1), self._kernel)\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0mlstm_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1983\u001b[0m       \u001b[0mare\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m   \"\"\"\n\u001b[0;32m-> 1985\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1986\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0madjoint_a\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1987\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only one of transpose_a and adjoint_a can be True.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6033\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6034\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6035\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6036\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6037\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5659\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5660\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5661\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5662\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5663\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   5595\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5596\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[0;32m-> 5597\u001b[0;31m                                                                 original_item))\n\u001b[0m\u001b[1;32m   5598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"rnn/lstm_cell/kernel:0\", shape=(21, 80), dtype=float32_ref) must be from the same graph as Tensor(\"concat:0\", shape=(?, 21), dtype=float32)."
     ]
    }
   ],
   "source": [
    "logits = RNN(xplaceholder, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_units = 50\n",
    "batch_size =1\n",
    "conv_layer = tf.contrib.rnn.Conv1DLSTMCell(num_units,input_shape=[1, 3],\n",
    "                                           kernel_shape=3,output_channels=1,\n",
    "                                          use_bias=True,forget_bias=1.0)#stride=3,\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "#val,state = tf.nn.dynamic_rnn(cell=conv_layer, inputs=train_x_cust, sequence_length=seq_length, dtype=tf.float64)\n",
    "#val,state = tf.nn.dynamic_rnn(cell=conv_layer, inputs=xplaceholder, sequence_length=seq_length, dtype=tf.float32)\n",
    "initial_state = conv_layer.zero_state(batch_size, dtype=tf.float32)\n",
    "val, state = tf.nn.dynamic_rnn(conv_layer, tf.expand_dims(xplaceholder, -1), initial_state=initial_state,dtype = tf.float32)\n",
    "val = tf.transpose(val, [1, 0, 2]) #axis [1,0,2] horizontal and vertical axes\n",
    "# are interchanged for 2D image;0-horizontal,1-vertical\n",
    "last = tf.gather(val, int(val.get_shape()[0]) - 1)\n",
    "weight = tf.Variable(tf.truncated_normal([num_hidden, int(yplaceholder.get_shape()[1])]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[yplaceholder.get_shape()[1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The argument 'cell' (Tensor(\"dropout/mul:0\", shape=(?, 1, 25), dtype=float32)) is not an RNNCell: 'output_size' property is missing, 'state_size' property is missing, either 'zero_state' or 'get_initial_state' method is required, is not callable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-24bcd8e38522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#output_cell = tf.layers.dense(rnn_cell, 1, tf.nn.relu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Get lstm cell output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mstatic_rnn\u001b[0;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[1;32m   1271\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0minferred\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mvia\u001b[0m \u001b[0mshape\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m   \"\"\"\n\u001b[0;32m-> 1273\u001b[0;31m   \u001b[0mrnn_cell_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_like_rnncell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cell\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1274\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs must be a sequence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36massert_like_rnncell\u001b[0;34m(cell_name, cell)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconditions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     raise TypeError(\"The argument {!r} ({}) is not an RNNCell: {}.\".format(\n\u001b[0;32m---> 97\u001b[0;31m         cell_name, cell, \", \".join(errors)))\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The argument 'cell' (Tensor(\"dropout/mul:0\", shape=(?, 1, 25), dtype=float32)) is not an RNNCell: 'output_size' property is missing, 'state_size' property is missing, either 'zero_state' or 'get_initial_state' method is required, is not callable."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "num_neurons = 25 #filters\n",
    "with graph.as_default():\n",
    "# other way of implementation\n",
    "    x = tf.unstack(xplaceholder, 3, 1)\n",
    "    dropout_prob = tf.placeholder(tf.float32)\n",
    "    conv_layer = tf.layers.conv1d(inputs=xplaceholder, filters=num_neurons, kernel_size=3, strides=3,\n",
    "        padding='same', activation = tf.nn.relu) #can change activation\n",
    "    #lstm_cell = tf.nn.rnn_cell.LSTMCell(n_hidden, forget_bias=1.0)\n",
    "    #pool = tf.nn.pool(lstm_cell, [3], 'MAX', 'SAME', strides = [3])\n",
    "    pool_1 = tf.layers.max_pooling1d(conv_layer, pool_size=3, strides=3, padding='SAME')\n",
    "    drop_out = tf.nn.dropout(pool_1, dropout_prob)\n",
    "    #dropout_wrapper = tf.contrib.rnn.DropoutWrapper(pool_1,input_keep_prob=(1-dropout_prob))\n",
    "    #lstm_cell = tf.contrib.rnn.LSTMBlockCell(num_units=num_neurons,use_peephole=False)\n",
    "    #rnn_cell = tf.contrib.rnn.MultiRNNCell([drop_out,lstm_cell]*1,state_is_tuple=False)\n",
    "    #output_cell = tf.layers.dense(rnn_cell, 1, tf.nn.relu)\n",
    "    # Get lstm cell output\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(drop_out, x, dtype=tf.float32)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell = tf.contrib.rnn.MultiRNNCell([\n",
    "\ttf.contrib.rnn.LSTMBlockCell(NUM_HIDDEN) for _ in range(NUM_LAYERS)\n",
    "])\n",
    "rnn_out, _ = tf.nn.dynamic_rnn(rnn_cell, embeddings, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_units=64, state_is_tuple=True)\n",
    "cell = tf.nn.rnn_cell.DropoutWrapper(cell=cell, output_keep_prob=0.5)\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell(cells=[cell] * 4, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  outputs_val, states_val = sess.run([outputs, states], \n",
    "                                     feed_dict={X: X_batch, seq_length: seq_length_batch})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 3, 1)\n",
      "(36, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x_cust,train_y_cust, scalar_train = prepare_training_data_tensorflow(train_x['fv_cost'], 3)\n",
    "test_x_cust,test_y_cust,scalar_test = prepare_training_data_tensorflow(test_x['fv_cost'], 3)\n",
    "print(train_x_cust.shape)\n",
    "print(test_x_cust.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other approach\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_periods = 3\n",
    "inputs = 1\n",
    "output = 1\n",
    "hidden = 25\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,num_periods,inputs])\n",
    "#y = tf.placeholder(tf.float32,[None,num_periods,output])\n",
    "y = tf.placeholder(tf.float32,[None])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units= hidden,activation=tf.nn.relu)\n",
    "rnn_output,states = tf.nn.dynamic_rnn(basic_cell,X,dtype=tf.float32)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "stacked_rnn_output = tf.reshape(rnn_output,[-1,hidden])\n",
    "#stacked_rnn_output = tf.reshape(rnn_output,[-1])\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_output, output)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, num_periods, output])\n",
    "#outputs = tf.reshape(stacked_outputs, [-1])\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all flags before declare\n",
    "\n",
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()    \n",
    "    keys_list = [keys for keys in flags_dict]    \n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(tf.flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 257669.44\n",
      "100 \tMSE: 71424.44\n",
      "200 \tMSE: 68341.62\n",
      "300 \tMSE: 67958.99\n",
      "400 \tMSE: 67757.8\n",
      "500 \tMSE: 67690.94\n",
      "600 \tMSE: 67670.58\n",
      "700 \tMSE: 67661.74\n",
      "800 \tMSE: 67655.78\n",
      "900 \tMSE: 67650.9\n",
      "[[[-0.53336775]\n",
      "  [-0.52872825]\n",
      "  [-0.5240464 ]]\n",
      "\n",
      " [[-0.52029777]\n",
      "  [-0.5212044 ]\n",
      "  [-0.51584023]]\n",
      "\n",
      " [[-0.519748  ]\n",
      "  [-0.51868016]\n",
      "  [-0.5187571 ]]\n",
      "\n",
      " [[-0.5198285 ]\n",
      "  [-0.51911056]\n",
      "  [-0.5192231 ]]\n",
      "\n",
      " [[-0.5177237 ]\n",
      "  [-0.515473  ]\n",
      "  [-0.51486087]]\n",
      "\n",
      " [[-0.5160373 ]\n",
      "  [-0.5135942 ]\n",
      "  [-0.5147239 ]]\n",
      "\n",
      " [[-0.5170448 ]\n",
      "  [-0.5139308 ]\n",
      "  [-0.51153594]]\n",
      "\n",
      " [[-0.51793116]\n",
      "  [-0.51467806]\n",
      "  [-0.5171018 ]]\n",
      "\n",
      " [[-0.51835555]\n",
      "  [-0.51920295]\n",
      "  [-0.520518  ]]\n",
      "\n",
      " [[-0.5169399 ]\n",
      "  [-0.5191648 ]\n",
      "  [-0.5166661 ]]\n",
      "\n",
      " [[-0.51837665]\n",
      "  [-0.5285798 ]\n",
      "  [-0.52507114]]\n",
      "\n",
      " [[-0.51821023]\n",
      "  [-0.5238525 ]\n",
      "  [-0.5174793 ]]\n",
      "\n",
      " [[-0.51812214]\n",
      "  [-0.5168929 ]\n",
      "  [-0.52077025]]\n",
      "\n",
      " [[-0.5150303 ]\n",
      "  [-0.521441  ]\n",
      "  [-0.5189402 ]]\n",
      "\n",
      " [[-0.51663065]\n",
      "  [-0.5235782 ]\n",
      "  [-0.52069795]]\n",
      "\n",
      " [[-0.5183123 ]\n",
      "  [-0.52129334]\n",
      "  [-0.5209099 ]]\n",
      "\n",
      " [[-0.51506025]\n",
      "  [-0.51355606]\n",
      "  [-0.51408696]]\n",
      "\n",
      " [[-0.5075707 ]\n",
      "  [-0.5178533 ]\n",
      "  [-0.51137716]]\n",
      "\n",
      " [[-0.5012084 ]\n",
      "  [-0.52040887]\n",
      "  [-0.51693565]]\n",
      "\n",
      " [[-0.50099015]\n",
      "  [-0.5246928 ]\n",
      "  [-0.5184316 ]]\n",
      "\n",
      " [[-0.4988311 ]\n",
      "  [-0.52085954]\n",
      "  [-0.5176194 ]]\n",
      "\n",
      " [[-0.502958  ]\n",
      "  [-0.52023226]\n",
      "  [-0.5152266 ]]\n",
      "\n",
      " [[-0.5220443 ]\n",
      "  [-0.517321  ]\n",
      "  [-0.51487917]]\n",
      "\n",
      " [[-0.49997014]\n",
      "  [-0.5110629 ]\n",
      "  [-0.51758224]]\n",
      "\n",
      " [[-0.4992715 ]\n",
      "  [-0.51919436]\n",
      "  [-0.5282285 ]]\n",
      "\n",
      " [[-0.49915105]\n",
      "  [-0.5182001 ]\n",
      "  [-0.5199231 ]]\n",
      "\n",
      " [[-0.5028464 ]\n",
      "  [-0.52059484]\n",
      "  [-0.5178255 ]]\n",
      "\n",
      " [[-0.5263986 ]\n",
      "  [-0.51722884]\n",
      "  [-0.5149923 ]]\n",
      "\n",
      " [[-0.5440777 ]\n",
      "  [-0.51334476]\n",
      "  [-0.5179591 ]]\n",
      "\n",
      " [[-0.5592467 ]\n",
      "  [-0.51506376]\n",
      "  [-0.5173273 ]]\n",
      "\n",
      " [[-0.58516395]\n",
      "  [-0.51923376]\n",
      "  [-0.51971686]]\n",
      "\n",
      " [[-0.5172765 ]\n",
      "  [-0.6296346 ]\n",
      "  [-0.51152664]]\n",
      "\n",
      " [[-0.54147625]\n",
      "  [-0.57318324]\n",
      "  [-0.5364202 ]]\n",
      "\n",
      " [[-0.53787476]\n",
      "  [-0.529691  ]\n",
      "  [-0.54909635]]\n",
      "\n",
      " [[-0.5231583 ]\n",
      "  [-0.5232641 ]\n",
      "  [-0.51972824]]\n",
      "\n",
      " [[-0.5201073 ]\n",
      "  [-0.51887405]\n",
      "  [-0.51736784]]]\n"
     ]
    }
   ],
   "source": [
    "tf.flags.DEFINE_integer(\"batch_size\", 37, \"Batch size during training\") \n",
    "tf.flags.DEFINE_integer(\"eval_batch_size\", 37, \"Batch size during evaluation\")\n",
    "tf.flags.DEFINE_integer(\"test_batch_size\", 37, \"Batch size for testing\")\n",
    "# above batch_size value works fine with value one as well but remember to run\n",
    "#del_all_flags function before declaring flags\n",
    "epochs = 1000\n",
    "with tf.Session() as sess:\n",
    "     init.run()\n",
    "     for ep in range(epochs):\n",
    "         sess.run(training_op, feed_dict = {X:train_x_cust, y:train_y_cust})\n",
    "         if ep%100 ==0:\n",
    "            mse = loss.eval(feed_dict = {X:train_x_cust, y:train_y_cust})\n",
    "            print(ep,\"\\tMSE:\",mse)\n",
    "     y_pred = sess.run(outputs, feed_dict = {X:test_x_cust})\n",
    "     print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.76316197 -0.73862634 -0.74221991 -0.64829467 -0.56661377 -0.50677036\n",
      " -0.45412357 -0.36753847 -0.27912729 -0.35985935 -0.42056837 -0.31465915\n",
      " -0.23698166 -0.18262504 -0.14319251 -0.05493859  0.07575444  0.20911232\n",
      "  0.32464201  0.40540166  0.51765344  0.63870508  0.36279695  0.38892744\n",
      "  0.39343426  0.51660125  0.66388579  0.76612264  0.85384363  1.\n",
      " -0.28655686 -0.9000785  -0.87877479 -0.79834174 -0.75466256 -0.7067018 ]\n",
      "[[[0.23436965 0.20983402 0.21342759 ... 0.26954942 0.22587024 0.17790948]\n",
      "  [0.2411591  0.21662346 0.22021704 ... 0.27633887 0.23265968 0.18469892]\n",
      "  [0.24155445 0.21701882 0.2206124  ... 0.27673422 0.23305504 0.18509428]]\n",
      "\n",
      " [[0.24248405 0.21794842 0.22154199 ... 0.27766382 0.23398463 0.18602387]\n",
      "  [0.23960562 0.21506999 0.21866356 ... 0.27478539 0.23110621 0.18314545]\n",
      "  [0.244101   0.21956537 0.22315894 ... 0.27928077 0.23560159 0.18764083]]\n",
      "\n",
      " [[0.24358357 0.21904794 0.22264152 ... 0.27876334 0.23508416 0.1871234 ]\n",
      "  [0.2455637  0.22102807 0.22462164 ... 0.28074347 0.23706429 0.18910353]\n",
      "  [0.24055399 0.21601836 0.21961193 ... 0.27573376 0.23205458 0.18409381]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.22999437 0.20545874 0.20905231 ... 0.26517414 0.22149496 0.1735342 ]\n",
      "  [0.24573083 0.2211952  0.22478877 ... 0.2809106  0.23723142 0.18927066]\n",
      "  [0.2380919  0.21355627 0.21714984 ... 0.27327167 0.22959249 0.18163173]]\n",
      "\n",
      " [[0.23930456 0.21476892 0.2183625  ... 0.27448433 0.23080514 0.18284438]\n",
      "  [0.24154337 0.21700773 0.22060131 ... 0.27672314 0.23304395 0.18508319]\n",
      "  [0.249689   0.22515337 0.22874694 ... 0.28486877 0.24118958 0.19322882]]\n",
      "\n",
      " [[0.24286498 0.21832935 0.22192292 ... 0.27804475 0.23436557 0.18640481]\n",
      "  [0.24331911 0.21878348 0.22237705 ... 0.27849888 0.2348197  0.18685893]\n",
      "  [0.24227907 0.21774343 0.22133701 ... 0.27745884 0.23377965 0.18581889]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_y_cust)\n",
    "print(y_pred - test_y_cust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
