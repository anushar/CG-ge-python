{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout   \n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import optimizers\n",
    "\n",
    "# Reading csv file\n",
    "#customers timeseries updated has data for 100 customers\n",
    "df = pd.read_csv(\"customers_timeseries_updated.csv\")\n",
    "#only using required columns for modelling\n",
    "df = df[['client_debtor_number','dates','fv_cost']]\n",
    "# number of unique customers in the data\n",
    "len(df['client_debtor_number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1015193  7370830  7806949  8459916  8119511  6860001  9890599  1434120\n",
      "  8069905  1385090  8131406  7945906  5744792  1810070  6400280  7411081\n",
      "  9982280  9934723  2062217  8056102  1186000  1136123  5851882  8600643\n",
      "  8436150  8191735  1431777  8485682  1563037 10005722  9346899  3494047\n",
      "  8665982  2134196  1119250  1069732  1934833  7983956  8097194  1215523\n",
      "  6185266  1979527  8056412  2267185  1139640  9574816  8276366  1674609\n",
      "  8529930  8223963  1595164  6524818  7987099  8206104  1345685  3447510\n",
      "  1167669  1146580  1773891  2069361  6769268  8186928  1411373  8380120\n",
      "  5045681  8690251  9895000 10005374  8285861  8491232  1351530  9706542\n",
      "  9977120  8392722  8468052  1931318  1233503  8542090  9049053  7322690\n",
      "  1140689  8369976  1532549  1555678  1571329  1620518  1595166  1645262\n",
      "  8344620  7530072  1080321  7819277  1462982  1881607  1895787  8367884\n",
      "  7772912  1172447  2034325  2063988  2053220]\n"
     ]
    }
   ],
   "source": [
    "print(df['client_debtor_number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# subsetting one customer data from the set\n",
    "# 1015193\n",
    "df_1015130 = df[df['client_debtor_number'] == 7370830]\n",
    "del df_1015130['client_debtor_number']\n",
    "\n",
    "# splitting train and test datasets \n",
    "#training 2010-2017, testing on 2018 data\\\n",
    "train_x = df_1015130[df_1015130['dates'].str.contains('/2018') == False]\n",
    "test_x = df_1015130[df_1015130['dates'].str.contains('/2018') == True]\n",
    "#resetting index values\n",
    "train_x.reset_index(drop=True,inplace=True)\n",
    "test_x.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#sorting data based on dates\n",
    "train_x['dates'] = pd.to_datetime(train_x['dates'],format= '%d/%m/%Y')\n",
    "train_x.sort_values(by='dates',inplace=True)\n",
    "test_x['dates'] = pd.to_datetime(test_x['dates'],format= '%d/%m/%Y')\n",
    "test_x.sort_values(by='dates',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2929, 1, 3)\n",
      "(2929,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anusha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "# lag_feature function is used to get new column in the dataframe with \n",
    "#lagged data,number of lags can be given as function parameter \n",
    "def lag_feature(df, lag=1):\n",
    "    if not type(df) == pd.DataFrame:\n",
    "        df = pd.DataFrame(df, columns=['fv_cost'])   \n",
    "    def rename_lag(ser, j):\n",
    "        ser.name = ser.name + f'_{j}'\n",
    "        return ser        \n",
    "    # add a column lagged by `i` steps\n",
    "    for i in range(1, lag + 1):\n",
    "        df = df.join(df.fv_cost.shift(i).pipe(rename_lag, i))\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "# Prepare training data function is used to scale the fv_cost values \n",
    "# between -1 to 1 and calls lag_feature to create lag columns \n",
    "def prepare_training_data(series_data, lag):\n",
    "    \" Converts a series of data into a lagged, scaled sample.\"\n",
    "    # scale training data\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    #when diff is used don't use values\n",
    "    #cost_vals = scaler.fit_transform(series_data.values.reshape(-1, 1))   \n",
    "    cost_vals = scaler.fit_transform(series_data.reshape(-1, 1))\n",
    "    # convert series to lagged features\n",
    "    cost_lagged = lag_feature(cost_vals, lag=lag)\n",
    "    # X, y format taking the first column (original time series) to be the y\n",
    "    X = cost_lagged.drop('fv_cost', axis=1).values\n",
    "    y = cost_lagged.fv_cost.values\n",
    "    \n",
    "    # keras expects 3 dimensional X\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])   \n",
    "    return X, y, scaler\n",
    "\n",
    "#Difference function is get lag difference values\n",
    "def difference(dataset):\n",
    "    interval=1\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        #print (\"iteration \",i)\n",
    "        value = (dataset.iloc[i] - dataset.iloc[i - interval])/(1+abs(dataset.iloc[i - interval]))\n",
    "        diff.append(value)\n",
    "    return diff\n",
    "\n",
    "# if you are using difference lag values use this code\n",
    "#diff_train = np.array(difference(train_x['fv_cost']))\n",
    "#diff_test = np.array(difference(test_x['fv_cost']))\n",
    "#train_x_cust,train_y_cust, scalar_train = prepare_training_data(diff_train, 3)\n",
    "#test_x_cust,test_y_cust,scalar_test = prepare_training_data(diff_test, 3)\n",
    "# preparing data on train and test fv_cost column values\n",
    "train_x_cust,train_y_cust, scalar_train = prepare_training_data(train_x['fv_cost'], 3)\n",
    "test_x_cust,test_y_cust,scalar_test = prepare_training_data(test_x['fv_cost'], 3)\n",
    "print(train_x_cust.shape)\n",
    "print(train_y_cust.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , ..., 15.78374772,\n",
       "       17.54404341, 19.30457443])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lag features of output/y value to use in future\n",
    "actual_cost_lag_2 = lag_feature(df_1015130['fv_cost'],2)\n",
    "actual_cost_lag_2 = actual_cost_lag_2.fv_cost.values\n",
    "actual_cost_lag_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for one timestep\n",
    "def lstm_model(train_x, train_y,lag=3,num_neurons=50):\n",
    "    # Model description\n",
    "    # lag is number of lags used to prepare the data\n",
    "    #lag =  3\n",
    "    # model parameters\n",
    "    #num_neurons = 50 #number of neurons/nodes for the layer\n",
    "    # actually we can give data in batches to the model\n",
    "    # number of samples in the data should be divisible by batch size\n",
    "    # we are giving all data for a customer as one batch\n",
    "    batch_size = 1  \n",
    "    # input_shape as required by LSTM layer\n",
    "    batch_input_shape=(batch_size, 1, lag)\n",
    "    # dropout rate used in dropout layer\n",
    "    dropout_rate =0.2\n",
    "    # instantiate a sequential model\n",
    "    model = Sequential()\n",
    "    #add convolution layer\n",
    "    # input_shape=(3,1) 3 lags columns and 1 y value\n",
    "    # when strides>1 you cannot have dilation>1\n",
    "    # activation_func options ['softmax', 'softplus', 'softsign', 'relu', \n",
    "    #                   'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "    # in conv1D layer we can modify filters,kernel_size,strides and activation\n",
    "    # parameters\n",
    "    model.add(Conv1D(filters=num_neurons,batch_size=1, kernel_size=3, strides=3, \n",
    "                 padding=\"same\",activation='linear',dilation_rate=1, \n",
    "                 input_shape=(1, 3),data_format='channels_first'))\n",
    "    # maxpooling layers tries to reduce the features by taking maximum value for\n",
    "    # window/pool size selected,strides and pool_size can be changed\n",
    "    model.add(MaxPooling1D(pool_size=3,strides=3, padding=\"same\"))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # add LSTM layer - stateful MUST be true here in \n",
    "    # order to learn the patterns within a series\n",
    "    model.add(LSTM(units=num_neurons, \n",
    "              batch_input_shape=batch_input_shape, return_sequences=False,# as we only want last hidden output \n",
    "              stateful=True))\n",
    "    # output layer\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    # compile the model with required loss and optimizer function\n",
    "    adam = optimizers.Adam(lr=0.01, decay=0.01)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "    model.fit(train_x, train_y, epochs=10, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 32s - loss: 0.0078\n",
      "Epoch 2/10\n",
      " - 33s - loss: 0.0074\n",
      "Epoch 3/10\n",
      " - 32s - loss: 0.0054\n",
      "Epoch 4/10\n",
      " - 33s - loss: 0.0044\n",
      "Epoch 5/10\n",
      " - 35s - loss: 0.0041\n",
      "Epoch 6/10\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model(train_x_cust,train_y_cust,3,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicitons on test data\n",
    "predictions_1 = model.predict(test_x_cust,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find 1lag of test_y_cust for comparision\n",
    "test_y_lag1 = lag_feature(test_y_cust,1).fv_cost.values\n",
    "test_y_lag1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split predictions into train and test\n",
    "pred_train = predictions_1[0:-90]\n",
    "pred_test = predictions_1[90:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model on predictions\n",
    "train_x_cust,train_y_cust, scalar_train = prepare_training_data(pred_train, 3)\n",
    "test_x_cust,test_y_cust,scalar_test = prepare_training_data(pred_test, 3)\n",
    "\n",
    "model_pred = lstm_model(train_x_cust,train_y_cust,3,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare second step predictions with original scaled test y values\n",
    "pred_2 = model.predict(test_x_cust,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse error with predictions and actual values\n",
    "#sqrt\n",
    "(mean_squared_error(test_y_lag1[-(len(pred_2)):],pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions iteratively\n",
    "# fv cost rest_index and sort values\n",
    "df_1015130.reset_index(drop=True,inplace=True)\n",
    "#sorting data based on dates\n",
    "df_1015130['dates'] = pd.to_datetime(df_1015130['dates'],format= '%d/%m/%Y')\n",
    "df_1015130.sort_values(by='dates',inplace=True)\n",
    "print (df_1015130.dates)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can change training window months later\n",
    "train_6m = df_1015130[(df_1015130['dates'].dt.year == 2018) & \n",
    "                      ~((df_1015130['dates'].dt.month == 7)|\n",
    "                      (df_1015130['dates'].dt.month == 8)|\n",
    "                      (df_1015130['dates'].dt.month == 9))]\n",
    "window_test_3m = df_1015130[(df_1015130['dates'].dt.year == 2018) &\n",
    "                            ((df_1015130['dates'].dt.month == 7)|\n",
    "                            (df_1015130['dates'].dt.month == 8)|\n",
    "                            (df_1015130['dates'].dt.month == 9))]\n",
    "\n",
    "print (train_6m)\n",
    "print (window_test_3m)\n",
    "#for i in range(0,4):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteratively run the model on predicitons\n",
    "data_train = train_6m['fv_cost']\n",
    "data_train.reset_index(drop=True,inplace=True)\n",
    "train_x_cust,train_y_cust, scalar_train = prepare_training_data(data_train, 3)\n",
    "pred_train = model.predict(train_x_cust,batch_size=1)\n",
    "\n",
    "test_fvcost = window_test_3m['fv_cost']\n",
    "test_fvcost.reset_index(drop=True,inplace=True)\n",
    "test_x_cust,test_y_cust,scalar_test = prepare_training_data(test_fvcost,3)\n",
    "test_pred = model.predict(test_x_cust,batch_size=1)\n",
    "#since input should be in 3 lag format\n",
    "pred_test = np.vstack([pred_train[-3:],test_pred[1]]) \n",
    "\n",
    "n=120\n",
    "error_list = []\n",
    "for i in range(1,n):\n",
    "    train_x_cust,train_y_cust, scalar_train = prepare_training_data(pred_train, 3)\n",
    "    test_x_cust,test_y_cust,scalar_test = prepare_training_data(pred_test, 3)\n",
    "    model_pred = lstm_model(train_x_cust,train_y_cust,3,50)\n",
    "    pred_2 = model.predict(test_x_cust,batch_size=1)\n",
    "    error_list.append(mean_squared_error(test_y_cust,pred_2))\n",
    "    print(\"Error at iteration \",i,mean_squared_error(test_y_cust,pred_2))\n",
    "    #update train and test datasets\n",
    "    pred_train=np.vstack([pred_train[i:],pred_test])\n",
    "    pred_test = np.vstack([pred_train[-3:],pred_2]) #input need to have 3 lags\n",
    "    print (\"prediction at \",i,pred_2)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(error_list)\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop for number of days with error < 0.5\n",
    "count = 0\n",
    "error_df = pd.DataFrame()\n",
    "for i in range(len(error_list)):\n",
    "    if(error_list[i] < 0.5):\n",
    "        error_df['iteration'] = i\n",
    "        error_df['error'] = error_list[i]\n",
    "        count = count+1\n",
    "    \n",
    "print(\"count\",count)\n",
    "print(\"length of error\",len(error_df))\n",
    "print(\"length of errorlist\", len(error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try with epochs,iterations and different train ,test sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loop over all customers\n",
    "for cust in df['client_debtor_number'].unique():\n",
    "    df_cust = df[df['client_debtor_number'] == cust]\n",
    "    del df_cust['client_debtor_number']\n",
    "    df_cust['dates'] = pd.to_datetime(df_cust['dates'],format= '%d/%m/%Y')\n",
    "    # splitting train and test datasets \n",
    "    #training 2010-2017, testing on 2018 data\\\n",
    "    train_x = df_cust[df_cust['dates'].dt.year == 2018]\n",
    "    test_x = df_cust[~(df_cust['dates'].dt.year == 2018)]\n",
    "    #resetting index values\n",
    "    train_x.reset_index(drop=True,inplace=True)\n",
    "    test_x.reset_index(drop=True,inplace=True)\n",
    "    #sorting data based on dates\n",
    "    train_x['dates'] = pd.to_datetime(train_x['dates'],format= '%d/%m/%Y')\n",
    "    train_x.sort_values(by='dates',inplace=True)\n",
    "    test_x['dates'] = pd.to_datetime(test_x['dates'],format= '%d/%m/%Y')\n",
    "    test_x.sort_values(by='dates',inplace=True)\n",
    "    # preparing data on train and test fv_cost column values\n",
    "    train_x_cust,train_y_cust, scalar_train = prepare_training_data(train_x['fv_cost'], 3)\n",
    "    test_x_cust,test_y_cust,scalar_test = prepare_training_data(test_x['fv_cost'], 3)\n",
    "    model = lstm_model(train_x_cust,train_y_cust,3,50)\n",
    "    # we can change training window months later\n",
    "    train_6m = df_cust[(df_cust['dates'].dt.year == 2018) & \n",
    "                      ~((df_cust['dates'].dt.month == 7)|\n",
    "                      (df_cust['dates'].dt.month == 8)|\n",
    "                      (df_cust['dates'].dt.month == 9))]\n",
    "    window_test_3m = df_cust[(df_cust['dates'].dt.year == 2018) &\n",
    "                            ((df_cust['dates'].dt.month == 7)|\n",
    "                            (df_cust['dates'].dt.month == 8)|\n",
    "                            (df_cust['dates'].dt.month == 9))]\n",
    "    #iteratively run the model on predicitons\n",
    "    data_train = train_6m['fv_cost']\n",
    "    data_train.reset_index(drop=True,inplace=True)\n",
    "    train_x_cust,train_y_cust, scalar_train = prepare_training_data(data_train, 3)\n",
    "    pred_train = model.predict(train_x_cust,batch_size=1)\n",
    "    test_fvcost = window_test_3m['fv_cost']\n",
    "    test_fvcost.reset_index(drop=True,inplace=True)\n",
    "    test_x_cust,test_y_cust,scalar_test = prepare_training_data(test_fvcost,3)\n",
    "    test_pred = model.predict(test_x_cust,batch_size=1)\n",
    "    #since input should be in 3 lag format\n",
    "    pred_test = np.vstack([pred_train[-3:],test_pred[1]]) \n",
    "    n=120\n",
    "    error_list = []\n",
    "    error_df = pd.DataFrame()\n",
    "    for i in range(1,n):\n",
    "        train_x_cust,train_y_cust, scalar_train = prepare_training_data(pred_train, 3)\n",
    "        test_x_cust,test_y_cust,scalar_test = prepare_training_data(pred_test, 3)\n",
    "        model_pred = lstm_model(train_x_cust,train_y_cust,3,50)\n",
    "        pred_2 = model.predict(test_x_cust,batch_size=1)\n",
    "        error_list.append(mean_squared_error(test_y_cust,pred_2))\n",
    "        error_df['iteration'] = i\n",
    "        error_df['error'] = mean_squared_error(test_y_cust,pred_2)\n",
    "        error_df['client_number'] = cust\n",
    "        print(\"Error at iteration \",i,mean_squared_error(test_y_cust,pred_2))\n",
    "        #update train and test datasets\n",
    "        pred_train=np.vstack([pred_train[i:],pred_test])\n",
    "        pred_test = np.vstack([pred_train[-3:],pred_2]) #input need to have 3 lags\n",
    "        print (\"prediction at \",i,pred_2)\n",
    "    print(\"completed loop for customer \",cust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with error values <0.1,0.001 and 0.5\n",
    "error_df.to_csv(\"predictions_for_client_120daysAhead.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_debtor_number</th>\n",
       "      <th>dates</th>\n",
       "      <th>fv_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1015193</td>\n",
       "      <td>10/07/2010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015193</td>\n",
       "      <td>11/07/2010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015193</td>\n",
       "      <td>12/07/2010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015193</td>\n",
       "      <td>13/07/2010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015193</td>\n",
       "      <td>14/07/2010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_debtor_number       dates  fv_cost\n",
       "0               1015193  10/07/2010      0.0\n",
       "1               1015193  11/07/2010      0.0\n",
       "2               1015193  12/07/2010      0.0\n",
       "3               1015193  13/07/2010      0.0\n",
       "4               1015193  14/07/2010      0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates                 01/01/2010  01/01/2011  01/01/2012  01/01/2013  \\\n",
      "client_debtor_number                                                   \n",
      "1015193                      0.0         0.0         0.0         0.0   \n",
      "1069732                      0.0         0.0         0.0         0.0   \n",
      "1080321                      0.0         0.0         0.0         0.0   \n",
      "1119250                      0.0         0.0         0.0         0.0   \n",
      "1136123                      0.0         0.0         0.0         0.0   \n",
      "\n",
      "dates                 01/01/2014  01/01/2015  01/01/2016  01/01/2017  \\\n",
      "client_debtor_number                                                   \n",
      "1015193                      0.0   10.038345  541.620754  171.863639   \n",
      "1069732                      0.0    0.000000    0.000000    0.000000   \n",
      "1080321                      0.0    0.000000    0.000000    0.000000   \n",
      "1119250                      0.0    0.000000    0.000000    0.000000   \n",
      "1136123                      0.0    0.000000    3.133835   -2.655382   \n",
      "\n",
      "dates                 01/01/2018  01/02/2010     ...      31/10/2016  \\\n",
      "client_debtor_number                             ...                   \n",
      "1015193               392.131466         0.0     ...      134.313206   \n",
      "1069732                 0.000000         0.0     ...        0.000000   \n",
      "1080321                 0.000000         0.0     ...        0.000000   \n",
      "1119250                 0.000000         0.0     ...        0.000000   \n",
      "1136123               -18.876382         0.0     ...        0.000000   \n",
      "\n",
      "dates                 31/10/2017  31/12/2010  31/12/2011  31/12/2012  \\\n",
      "client_debtor_number                                                   \n",
      "1015193               263.473737         0.0         0.0         0.0   \n",
      "1069732                 0.000000         0.0         0.0         0.0   \n",
      "1080321                 0.000000         0.0         0.0         0.0   \n",
      "1119250                 0.000000         0.0         0.0         0.0   \n",
      "1136123                 0.000000         0.0         0.0         0.0   \n",
      "\n",
      "dates                 31/12/2013  31/12/2014  31/12/2015  31/12/2016  \\\n",
      "client_debtor_number                                                   \n",
      "1015193                      0.0     10.0551  540.320451  170.023487   \n",
      "1069732                      0.0      0.0000    0.000000    0.000000   \n",
      "1080321                      0.0      0.0000    0.000000    0.000000   \n",
      "1119250                      0.0      0.0000    0.000000    0.000000   \n",
      "1136123                      0.0      0.0000    2.611355   -2.896586   \n",
      "\n",
      "dates                 31/12/2017  \n",
      "client_debtor_number              \n",
      "1015193               388.717815  \n",
      "1069732                 0.000000  \n",
      "1080321                 0.000000  \n",
      "1119250                 0.000000  \n",
      "1136123               -19.630126  \n",
      "\n",
      "[5 rows x 3192 columns]\n"
     ]
    }
   ],
   "source": [
    "# cluster error_data customers dataframe\n",
    "#Transform\n",
    "pivot_data = df.pivot_table(index='client_debtor_number',\n",
    "                      columns='dates',values='fv_cost',aggfunc='mean')\n",
    "print(pivot_data.head())\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(pivot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method KMeans.score of KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=0, tol=0.0001, verbose=0)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25633b00>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#elbow graph\n",
    "from sklearn.metrics import silhouette_score\n",
    "sse = {}\n",
    "for k in range(1, 20):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(pivot_data)\n",
    "    #print(data[\"clusters\"])\n",
    "   # sil_coeff = silhouette_score(pivot_data, kmeans.labels_, metric='euclidean')\n",
    "    pivot_data[\"clusters\"] = kmeans.labels_\n",
    "    #print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(k, sil_coeff))\n",
    "    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
